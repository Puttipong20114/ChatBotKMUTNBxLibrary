import os
import google.generativeai as genai
import pandas as pd
import streamlit as st
from prompt import PROMPT_WORKAW
from google.generativeai.types import HarmCategory, HarmBlockThreshold
from document_reader import get_kmutnb_summary

# ‚úÖ ‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏Ç‡∏≠: ‡πÑ‡∏°‡πà‡πÅ‡∏ï‡∏∞‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ô‡∏µ‡πâ
genai.configure(api_key="AIzaSyC9-PpmFwyEDe-rsGhZmyzV5bsDbw7ILGg")

# ----------------- CONFIG -----------------
generation_config = {
    "temperature": 0.0,
    "top_p": 0.90,
    "top_k": 40,
    "max_output_tokens": 2048,
    "response_mime_type": "text/plain",
    "candidate_count": 1,
}

SAFETY_SETTINGS = {
    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE
}

# ----------------- SYNONYMS -----------------
SYNONYMS = {
    "‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏≥‡∏Å‡∏≤‡∏£": ["‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏õ‡∏¥‡∏î-‡∏õ‡∏¥‡∏î", "‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á‡∏ó‡∏≥‡∏Å‡∏≤‡∏£", "‡πÄ‡∏ß‡∏•‡∏≤‡πÉ‡∏´‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£"],
    "‡∏õ‡∏¥‡∏î‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£": ["‡∏ß‡∏±‡∏ô‡∏´‡∏¢‡∏∏‡∏î", "‡∏õ‡∏¥‡∏î‡∏ó‡∏≥‡∏Å‡∏≤‡∏£"],
    "‡∏≠‡∏≤‡∏Ñ‡∏≤‡∏£‡∏ô‡∏ß‡∏°‡∏¥‡∏ô‡∏ó‡∏£‡∏£‡∏≤‡∏ä‡∏¥‡∏ô‡∏µ": ["‡∏≠‡∏≤‡∏Ñ‡∏≤‡∏£‡∏´‡πâ‡∏≠‡∏á‡∏™‡∏°‡∏∏‡∏î", "‡∏ï‡∏∂‡∏Å‡∏´‡πâ‡∏≠‡∏á‡∏™‡∏°‡∏∏‡∏î", "‡πÇ‡∏ã‡∏ô B"],
    "‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà": ["‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡∏±‡πâ‡∏á", "Location", "Address"],
    "‡∏Å‡∏≤‡∏£‡πÄ‡∏î‡∏¥‡∏ô‡∏ó‡∏≤‡∏á": ["‡∏ß‡∏¥‡∏ò‡∏µ‡∏°‡∏≤", "‡∏ó‡∏≤‡∏á‡πÄ‡∏Ç‡πâ‡∏≤‡∏´‡πâ‡∏≠‡∏á‡∏™‡∏°‡∏∏‡∏î", "‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡∏≤‡∏á"],
    "Call Center": ["‡∏®‡∏π‡∏ô‡∏¢‡πå‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£", "‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç‡πÇ‡∏ó‡∏£‡∏®‡∏±‡∏û‡∏ó‡πå", "‡πÄ‡∏ö‡∏≠‡∏£‡πå‡πÇ‡∏ó‡∏£"],
    "Email": ["‡∏≠‡∏µ‡πÄ‡∏°‡∏•", "‡∏ä‡πà‡∏≠‡∏á‡∏ó‡∏≤‡∏á‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏ó‡∏≤‡∏á‡∏≠‡∏µ‡πÄ‡∏°‡∏•"],
    "Facebook": ["‡πÄ‡∏ü‡∏ã‡∏ö‡∏∏‡πä‡∏Å", "‡πÅ‡∏ü‡∏ô‡πÄ‡∏û‡∏à", "Facebook page"],
    "Line": ["‡πÑ‡∏•‡∏ô‡πå", "Line Official"],
    "‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå": ["‡πÄ‡∏ß‡πá‡∏ö", "web", "‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå‡∏Ç‡∏≠‡∏á‡∏´‡πâ‡∏≠‡∏á‡∏™‡∏°‡∏∏‡∏î", "library site"],
    "‡∏¢‡∏∑‡∏°‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠": ["‡∏Å‡∏≤‡∏£‡∏¢‡∏∑‡∏°‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£"],
    "‡∏Ñ‡∏∑‡∏ô‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠": ["‡∏™‡πà‡∏á‡∏Ñ‡∏∑‡∏ô", "‡∏Å‡∏≤‡∏£‡∏Ñ‡∏∑‡∏ô‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£"],
    "‡∏ï‡πà‡∏≠‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠": ["‡∏ï‡πà‡∏≠‡∏≠‡∏≤‡∏¢‡∏∏‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠", "‡∏Ç‡∏¢‡∏≤‡∏¢‡πÄ‡∏ß‡∏•‡∏≤", "Renew"],
    "‡∏à‡∏≠‡∏á‡∏´‡πâ‡∏≠‡∏á‡∏≠‡πà‡∏≤‡∏ô‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠": ["‡∏Å‡∏≤‡∏£‡∏™‡∏≥‡∏£‡∏≠‡∏á‡∏´‡πâ‡∏≠‡∏á", "‡∏Å‡∏≤‡∏£‡∏à‡∏≠‡∏á‡∏´‡πâ‡∏≠‡∏á‡∏ï‡∏¥‡∏ß‡πÄ‡∏ï‡∏≠‡∏£‡πå", "Smart Room", "KM Rooms", "‡∏´‡πâ‡∏≠‡∏á‡∏ï‡∏¥‡∏ß"],
    "‡∏à‡∏≠‡∏á‡∏ó‡∏µ‡πà‡∏ô‡∏±‡πà‡∏á": ["‡∏Å‡∏≤‡∏£‡∏™‡∏≥‡∏£‡∏≠‡∏á‡∏ó‡∏µ‡πà‡∏ô‡∏±‡πà‡∏á", "‡∏Å‡∏≤‡∏£‡∏à‡∏≠‡∏á‡πÇ‡∏ï‡πä‡∏∞‡∏≠‡πà‡∏≤‡∏ô"],
    "‡∏´‡πâ‡∏≠‡∏á‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡∏Ñ‡πâ‡∏ô‡∏Ñ‡∏ß‡πâ‡∏≤": ["‡∏´‡πâ‡∏≠‡∏á‡∏≠‡πà‡∏≤‡∏ô‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠", "‡∏´‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏Å‡∏•‡∏∏‡πà‡∏°", "KM Rooms"],
    "Quiet Zone": ["‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏á‡∏µ‡∏¢‡∏ö", "‡πÇ‡∏ã‡∏ô‡∏≠‡πà‡∏≤‡∏ô‡πÄ‡∏á‡∏µ‡∏¢‡∏ö"],
    "KM Stands": ["‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡∏¥‡∏ß‡∏Å‡∏•‡∏∏‡πà‡∏°"],
    "WiFi": ["‡∏≠‡∏¥‡∏ô‡πÄ‡∏ó‡∏≠‡∏£‡πå‡πÄ‡∏ô‡πá‡∏ï‡πÑ‡∏£‡πâ‡∏™‡∏≤‡∏¢", "‡πÄ‡∏Ñ‡∏£‡∏∑‡∏≠‡∏Ç‡πà‡∏≤‡∏¢‡πÑ‡∏£‡πâ‡∏™‡∏≤‡∏¢"],
    "Smart TV": ["‡πÇ‡∏ó‡∏£‡∏ó‡∏±‡∏®‡∏ô‡πå‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞"],
    "‡∏¢‡∏∑‡∏°‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏´‡πâ‡∏≠‡∏á‡∏™‡∏°‡∏∏‡∏î": ["Interlibrary Loan", "‡∏Å‡∏≤‡∏£‡∏¢‡∏∑‡∏°‡∏Ç‡πâ‡∏≤‡∏°‡∏™‡∏≤‡∏Ç‡∏≤"],
    "Book Delivery": ["‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏™‡πà‡∏á‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠‡∏ñ‡∏∂‡∏á‡∏ö‡πâ‡∏≤‡∏ô", "‡∏™‡πà‡∏á‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠"],
    "DDS": ["Document Delivery Service", "‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏™‡πà‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£"],
    "‡∏Ñ‡πà‡∏≤‡∏õ‡∏£‡∏±‡∏ö": ["‡∏Ñ‡πà‡∏≤‡∏ò‡∏£‡∏£‡∏°‡πÄ‡∏ô‡∏µ‡∏¢‡∏°‡∏•‡πà‡∏≤‡∏ä‡πâ‡∏≤", "‡∏Ñ‡πà‡∏≤‡∏ä‡∏≥‡∏£‡∏∞‡∏•‡πà‡∏≤‡∏ä‡πâ‡∏≤", "Fine"],
    "‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠‡∏Ñ‡πâ‡∏≤‡∏á‡∏ä‡∏≥‡∏£‡∏∞": ["‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠‡πÄ‡∏Å‡∏¥‡∏ô‡∏Å‡∏≥‡∏´‡∏ô‡∏î", "Overdue"],
    "‡∏£‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ö‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏´‡πâ‡∏≠‡∏á‡∏™‡∏°‡∏∏‡∏î": ["‡∏Å‡∏ï‡∏¥‡∏Å‡∏≤", "‡∏Å‡∏é‡∏Ç‡πâ‡∏≠‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö"],
    "E-Project": ["‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå"],
    "E-Thesis": ["‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏ô‡∏¥‡∏û‡∏ô‡∏ò‡πå‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå"],
    "E-Journal": ["‡∏ß‡∏≤‡∏£‡∏™‡∏≤‡∏£‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå"],
    "E-Proceeding": ["‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏ä‡∏∏‡∏°‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå"],
    "WebOPAC": ["‡∏£‡∏∞‡∏ö‡∏ö‡∏™‡∏∑‡∏ö‡∏Ñ‡πâ‡∏ô", "Online Catalog"],
    "‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö‡πÄ‡∏Å‡πà‡∏≤": ["Past Exam Papers", "‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á"],
    "‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•": ["Online Database", "‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå"],
    "Proxy": ["‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Proxy"],
    "OpenAthens": ["‡∏•‡πá‡∏≠‡∏Ñ‡∏≠‡∏¥‡∏ô OpenAthens"],
    "‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç‡πÇ‡∏ó‡∏£‡∏®‡∏±‡∏û‡∏ó‡πå": ["Call Center", "‡πÄ‡∏ö‡∏≠‡∏£‡πå‡πÇ‡∏ó‡∏£", "‡∏®‡∏π‡∏ô‡∏¢‡πå‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£"],
    "‡∏®‡∏π‡∏ô‡∏¢‡πå‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡πÄ‡∏Ñ‡∏£‡∏∑‡∏≠‡∏Ç‡πà‡∏≤‡∏¢": ["‡∏™‡∏≥‡∏ô‡∏±‡∏Å‡∏Ñ‡∏≠‡∏°‡∏û‡∏¥‡∏ß‡πÄ‡∏ï‡∏≠‡∏£‡πå"],
    "‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏ö‡∏±‡∏ï‡∏£": ["International Patent Classification"],
    "‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô": ["ASTM"],
    "‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡πÅ‡∏•‡∏∞‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ": ["ScienceDirect", "IEEE", "SpringerLink"],
    "‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡πÄ‡∏Ç‡∏ï‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏Ø": ["‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û"],
    "‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡πÄ‡∏Ç‡∏ï‡∏õ‡∏£‡∏≤‡∏à‡∏µ‡∏ô": ["‡∏õ‡∏£‡∏≤‡∏à‡∏µ‡∏ô‡∏ö‡∏∏‡∏£‡∏µ"],
    "‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡πÄ‡∏Ç‡∏ï‡∏£‡∏∞‡∏¢‡∏≠‡∏á": ["‡∏£‡∏∞‡∏¢‡∏≠‡∏á"],
}

def expand_synonyms(text: str) -> list:
    """‡∏Ç‡∏¢‡∏≤‡∏¢‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏à‡∏≤‡∏Å SYNONYMS"""
    expanded = set()
    lower = text.lower()
    for key, alts in SYNONYMS.items():
        if key.lower() in lower:
            for a in alts:
                expanded.add(a)
        for a in alts:
            if a.lower() in lower:
                expanded.add(key)
                expanded.update([x for x in alts if x != a])
    return sorted(expanded)

# ----------------- MODEL (Gemini 2.5) -----------------
@st.cache_resource(show_spinner=False)
def get_model():
    return genai.GenerativeModel(
        model_name="gemini-2.5-flash",  
        safety_settings=SAFETY_SETTINGS,
        generation_config=generation_config,
        system_instruction=PROMPT_WORKAW
    )

model = get_model()

# ----------------- PDF READER (‡∏≠‡πà‡∏≤‡∏ô‡∏ó‡∏∏‡∏Å‡∏´‡∏ô‡πâ‡∏≤) -----------------
def read_full_pdf(pdf_path: str) -> str:
    """‡∏≠‡πà‡∏≤‡∏ô PDF ‡∏ó‡∏∏‡∏Å‡∏´‡∏ô‡πâ‡∏≤‡∏î‡πâ‡∏ß‡∏¢ PyPDF2"""
    try:
        import PyPDF2
        text = ""
        with open(pdf_path, 'rb') as file:
            pdf_reader = PyPDF2.PdfReader(file)
            total_pages = len(pdf_reader.pages)
            
            for page_num in range(total_pages):
                page = pdf_reader.pages[page_num]
                text += page.extract_text() + "\n\n"
        
        return text.strip()
    except ImportError:
        st.error("‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á PyPDF2: pip install PyPDF2")
        return ""
    except Exception as e:
        st.error(f"Error reading PDF: {e}")
        return ""

# ----------------- FILE PATH MANAGEMENT -----------------
def find_dataset_file():
    """‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå dataset ‡∏à‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡∏ó‡∏µ‡πà"""
    possible_paths = [
        "DataSetLibraly.pdf",
        "./DataSetLibraly.pdf",
        os.path.join(os.path.dirname(__file__), "DataSetLibraly.pdf"),
        os.path.join(os.getcwd(), "DataSetLibraly.pdf"),
        "/app/DataSetLibraly.pdf",
        "/mount/src/DataSetLibraly.pdf",
        os.path.join("data", "DataSetLibraly.pdf"),
        os.path.join("assets", "DataSetLibraly.pdf"),
        os.path.join("documents", "DataSetLibraly.pdf"),
        "dataset_library.pdf",
        "DataSetLibrary.pdf",
    ]

    for path in possible_paths:
        if os.path.exists(path):
            return path
    return None

def get_dataset_path():
    """‡∏´‡∏≤ path ‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå dataset ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÅ‡∏™‡∏î‡∏á debug info"""
    found_path = find_dataset_file()
    if found_path:
        return found_path

    st.sidebar.write("üîç **Debug Info:**")
    st.sidebar.write(f"Current working directory: `{os.getcwd()}`")
    try:
        script_dir = os.path.dirname(__file__)
    except NameError:
        script_dir = "(no __file__ in this env)"
    st.sidebar.write(f"Script directory: `{script_dir}`")

    try:
        files = os.listdir(os.getcwd())
        pdf_files = [f for f in files if f.lower().endswith('.pdf')]
        st.sidebar.write(f"PDF files found: {pdf_files}")
        st.sidebar.write(f"All files in current dir: {files[:10]}...")
    except Exception as e:
        st.sidebar.write(f"Error listing files: {e}")

    return None

# ----------------- IO & CACHE -----------------
@st.cache_data(show_spinner=True)
def load_kmutnb_summary(path: str) -> str:
    """Load ‡πÅ‡∏•‡∏∞ cache ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å PDF (‡∏≠‡πà‡∏≤‡∏ô‡∏ó‡∏∏‡∏Å‡∏´‡∏ô‡πâ‡∏≤)"""
    try:
        # ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ read_full_pdf ‡∏Å‡πà‡∏≠‡∏ô
        content = read_full_pdf(path)
        if content:
            return content
        # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ ‡πÉ‡∏ä‡πâ document_reader ‡πÄ‡∏î‡∏¥‡∏°
        return get_kmutnb_summary(path)
    except Exception as e:
        return f"Error loading PDF: {str(e)}"

# ----------------- UPLOAD FALLBACK -----------------
def handle_file_upload():
    """‡πÉ‡∏´‡πâ user ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏≠‡∏á‡∏ñ‡πâ‡∏≤‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠"""
    st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå DataSetLibraly.pdf ‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö")
    st.info("üí° ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå dataset ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì")

    uploaded_file = st.file_uploader(
        "‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå PDF Dataset",
        type=['pdf'],
        help="‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå DataSetLibraly.pdf ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏ü‡∏•‡πå PDF ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡πâ‡∏≠‡∏á‡∏™‡∏°‡∏∏‡∏î KMUTNB"
    )

    if uploaded_file is not None:
        temp_path = f"temp_{uploaded_file.name}"
        with open(temp_path, "wb") as f:
            f.write(uploaded_file.getbuffer())

        st.success(f"‚úÖ ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå {uploaded_file.name} ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß")
        return temp_path

    return None

# ----------------- UI -----------------
def clear_history():
    st.session_state["messages"] = [
        {"role": "model", "content": "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ! ‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡πÉ‡∏´‡πâ‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏´‡πâ‡∏≠‡∏á‡∏™‡∏°‡∏∏‡∏î KMUTNB"}
    ]
    st.session_state.pop("chat_session", None)
    st.rerun()

with st.sidebar:
    if st.button("Clear History"):
        clear_history()

    st.markdown("---")
    st.subheader("üìÅ File Status")

st.title("üí¨ KMUTNB Library Chatbot")

if "messages" not in st.session_state:
    st.session_state["messages"] = [
        {
            "role": "model",
            "content": "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ! ‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡πÉ‡∏´‡πâ‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏´‡πâ‡∏≠‡∏á‡∏™‡∏°‡∏∏‡∏î KMUTNB",
        }
    ]

# ----------------- LOAD DATASET -----------------
file_path = get_dataset_path()

if file_path is None:
    file_path = handle_file_upload()

if file_path is None:
    st.error("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå dataset ‡πÑ‡∏î‡πâ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏´‡∏£‡∏∑‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á")
    st.stop()

with st.sidebar:
    st.success(f"‚úÖ Using file: `{os.path.basename(file_path)}`")
    st.caption(f"Full path: `{file_path}`")

try:
    file_content = load_kmutnb_summary(file_path)
    if isinstance(file_content, str) and file_content.startswith("Error"):
        st.error(file_content)
        st.info("üí° ‡∏•‡∏≠‡∏á‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå PDF ‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡∏°‡πà")
        st.stop()
    else:
        with st.sidebar:
            st.info(f"üìÑ Content loaded: {len(file_content)} characters")
except Exception as e:
    st.error(f"Error reading file: {e}")
    st.stop()

# ----------------- CREATE / REUSE CHAT SESSION -----------------
def ensure_chat_session():
    if "chat_session" not in st.session_state:
        base_history = [
            {
                "role": "model",
                "parts": [{"text": "‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏´‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÅ‡∏ô‡∏ö‡πÑ‡∏ß‡πâ"}],
            },
            {
                "role": "user",
                "parts": [{
                    "text": (
                        "‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• KMUTNB Library ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î:\n\n"
                        + file_content
                    )
                }],
            },
        ]
        st.session_state["chat_session"] = model.start_chat(history=base_history)

ensure_chat_session()

# ----------------- RENDER HISTORY -----------------
def render_messages(limit_last:int = 20):
    for msg in st.session_state["messages"][-limit_last:]:
        st.chat_message(msg["role"]).write(msg["content"])

render_messages()

# ----------------- HANDLE INPUT -----------------
prompt = st.chat_input(placeholder="‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö KMUTNB Library ‚ú®")

def trim_history(max_pairs:int = 8):
    """‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß history ‡πÉ‡∏ô UI"""
    msgs = st.session_state["messages"]
    if len(msgs) > (2 * max_pairs + 1):
        st.session_state["messages"] = msgs[-(2 * max_pairs + 1):]

def generate_response(user_text: str):
    st.session_state["messages"].append({"role": "user", "content": user_text})
    st.chat_message("user").write(user_text)

    # ‡πÇ‡∏´‡∏°‡∏î‡∏™‡∏±‡πâ‡∏ô ‡πÜ ‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì
    if user_text.lower().startswith("add") or user_text.lower().endswith("add"):
        reply = "‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥"
        st.session_state["messages"].append({"role": "model", "content": reply})
        st.chat_message("model").write(reply)
        trim_history()
        return

    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° prompt ‡πÅ‡∏ö‡∏ö‡πÑ‡∏°‡πà‡πÄ‡∏™‡∏£‡∏¥‡∏°‡∏Ñ‡∏≥
    syns = expand_synonyms(user_text)
    syn_hint = f" (‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á: {', '.join(syns)})" if syns else ""
    
    final_prompt = f"""{user_text}{syn_hint}

‡∏Å‡∏é‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö:
- ‡∏ï‡∏≠‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÉ‡∏ô Dataset
- ‡∏´‡πâ‡∏≤‡∏°‡πÅ‡∏ï‡πà‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö ‡∏´‡πâ‡∏≤‡∏°‡∏Ñ‡∏≤‡∏î‡πÄ‡∏î‡∏≤
- ‡∏ï‡∏≠‡∏ö‡∏™‡∏±‡πâ‡∏ô ‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö ‡∏ï‡∏£‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô
- ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≥‡∏ß‡πà‡∏≤ "‡∏Ñ‡∏£‡∏±‡∏ö" ‡∏´‡∏£‡∏∑‡∏≠ "‡∏Ñ‡πà‡∏∞"
- ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡∏ß‡πà‡∏≤ "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡∏µ‡πâ‡πÉ‡∏ô Dataset ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠ 02-555-2000" """

    placeholder = st.chat_message("model")
    stream_box = placeholder.empty()
    collected = []

    try:
        for chunk in st.session_state["chat_session"].send_message(final_prompt, stream=True):
            piece = getattr(chunk, "text", None)
            if piece:
                collected.append(piece)
                stream_box.write("".join(collected))
        final_text = "".join(collected).strip() or "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"
            
    except Exception as e:
        final_text = f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}"

    st.session_state["messages"].append({"role": "model", "content": final_text})
    trim_history()

if prompt:
    generate_response(prompt)